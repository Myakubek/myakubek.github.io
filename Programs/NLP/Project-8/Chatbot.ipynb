{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c0a1320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\myaku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\myaku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\myaku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Book & Library Chatbot Assistant\n",
    "\n",
    "Keeps track of your books, their ratings, and outputs recommendations based on NLP\n",
    "'''\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae9a3182",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15928\\2154912754.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# LOAD NLP FROM SPACY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"en_core_web_lg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# LOAD IN THE DATAFRAME OF BOOKS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbook_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"books.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\";\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"latin-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \"\"\"\n\u001b[1;32m---> 54\u001b[1;33m     return util.load_model(\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[index]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "# LOAD NLP FROM SPACY\n",
    "#pip install spacy && python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# LOAD IN THE DATAFRAME OF BOOKS\n",
    "book_df = pd.read_csv(\"books.csv\", sep=\";\", error_bad_lines=False, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf550642",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "-----------------\n",
    "CHECK IF ALL STRING ARE PRESENT IN TEXT\n",
    "-----------------\n",
    "'''\n",
    "def check_all_present(string_list, text):\n",
    "    for string in string_list:\n",
    "        if string not in text.lower():\n",
    "            return False\n",
    "    return True\n",
    "'''\n",
    "-----------------\n",
    "EXTRACT BOOK TITLE\n",
    "-----------------\n",
    "'''\n",
    "def extract_title(text):\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"WORK_OF_ART\":\n",
    "            return ent.text\n",
    "    return None\n",
    "'''\n",
    "-----------------\n",
    "EXTRACT RATING/REVIEW\n",
    "-----------------\n",
    "'''\n",
    "def check_any_present(input_string, string_list):\n",
    "    for string in string_list:\n",
    "        if string in input_string:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ed25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interact_with_chatbot(assistant, user_id):\n",
    "    print(\"Welcome to the Personal Book and Movie chatbot!\")\n",
    "    print(\"Type 'quit' to exit.\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(f\"{user_id}: \")\n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "\n",
    "        response = assistant.respond(user_id, user_input)\n",
    "        print(f\"Assistant: {response}\")\n",
    "\n",
    "    assistant.save_user_data()\n",
    "    print(\"Goodbye!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed6a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.book_ratings = {}\n",
    "        self.name_prompt = False\n",
    "        self.rating_prompt = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616b4c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonalAssistant:\n",
    "    '''\n",
    "    -----------------\n",
    "    CHATBOT INTIALIZATION\n",
    "    -----------------\n",
    "    '''\n",
    "    def __init__(self, user_data_file):\n",
    "        self.user_data_file = user_data_file\n",
    "        self.user = self.load_user_data()\n",
    "    '''\n",
    "    -----------------\n",
    "    USER DATA FUNCTIONS\n",
    "    -----------------\n",
    "    '''\n",
    "    def load_user_data(self):\n",
    "        try:\n",
    "            with open(self.user_data_file, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        except (FileNotFoundError, EOFError):\n",
    "            return {}\n",
    "\n",
    "    def save_user_data(self):\n",
    "        with open(self.user_data_file, 'wb') as f:\n",
    "            pickle.dump(self.user, f)\n",
    "\n",
    "    def get_user_model(self, user_id):\n",
    "        if user_id not in self.user:\n",
    "            self.user[user_id] = UserModel(\"unknown\")\n",
    "        return self.user[user_id]\n",
    "    \n",
    "    '''\n",
    "    -----------------\n",
    "    CHAT RESPONSE HANDLING FUNCTIONS\n",
    "    -----------------\n",
    "    '''\n",
    "    def respond(self, user_id, text):\n",
    "        #LOAD USER DATA\n",
    "        user_model = self.get_user_model(user_id)\n",
    "\n",
    "        #CHANGE NAME - If flagged, use POS tagging or get input and set as the user's name\n",
    "        if user_model.name_prompt:\n",
    "            tagged_text = pos_tag(word_tokenize(text))\n",
    "            first_name, last_name = None, None\n",
    "            for i, (word, pos) in enumerate(tagged_text):\n",
    "                if pos == 'NNP':\n",
    "                    if not first_name:\n",
    "                        first_name = word.capitalize()\n",
    "                    else:\n",
    "                        last_name = word.capitalize()\n",
    "                        break\n",
    "            if not first_name:\n",
    "                user_model.name = text\n",
    "            else:\n",
    "                user_model.name = f\"{first_name} {last_name}\" if last_name else first_name\n",
    "            user_model.name_prompt = False\n",
    "            return f'Alright, i\\'ve set your name as {user_model.name}'\n",
    "        \n",
    "        # NAME PROMPT IF DNE - If user doesn't have a name set the flag\n",
    "        if user_model.name == 'unknown':\n",
    "            user_model.name_prompt = True\n",
    "            return f\"Hello!, I've noticed I don't know your name in my knowledge base. Could you provide your first name so I know how to address you?\"\n",
    "        \n",
    "        #CHANGE NAME - Change the user's name\n",
    "        if check_all_present(['change', 'name'], text):\n",
    "            user_model.name_prompt = True\n",
    "            return f'Alright, let me know what you want to change your name to'\n",
    "        \n",
    "        #CHECK NAME - Print the user's name\n",
    "        if check_all_present(['what', 'name'], text):\n",
    "            return f\"Your name is {user_model.name}\"      \n",
    "        \n",
    "        #DETECT AND STORE RATINGS - When the user is giving their review for a book/rating.\n",
    "        if re.search(r'rate.*?(\\d+)', text):\n",
    "            title = extract_title(text)\n",
    "            rating = int(re.search(r'\\d+', text).group())\n",
    "            \n",
    "            user_model.book_ratings[title.lower()] = rating\n",
    "            return f\"Alright, I've added {title.lower()} to your book ratings with a rating of {rating}\"\n",
    "            \n",
    "        #PRINT RATINGS FOR CATEGORY\n",
    "        if \"ratings\" in text.lower():\n",
    "            category = re.search(r'ratings for (\\w+)', text, re.IGNORECASE)\n",
    "            if category:\n",
    "                if category.group(1).lower() == 'books':\n",
    "                    items = user_model.book_ratings\n",
    "                elif category.group(1).lower() == 'movies':\n",
    "                    items = user_model.movie_ratings\n",
    "                response = f\"{user_model.name}, your ratings for {category.group(1).lower()} are:\\n\"\n",
    "                for item, rating in items.items():\n",
    "                    response += f\"- {item}: {rating}/10\\n\"\n",
    "                return response\n",
    "            else:\n",
    "                return f\"I couldn't find any ratings for the specified category, {user_model.name}.\"\n",
    "\n",
    "        #HELLO RESPONSE\n",
    "        if any(user_input in text for user_input in ['hello', 'hi', 'greetings']):\n",
    "            return f\"Hello, {user_model.name}! How can I help you today?\" \n",
    "        \n",
    "        #DOCUMENTATION\n",
    "        if check_any_present(['documentation', 'docs', 'help', 'tutorial']):\n",
    "            return f\"Here's a list of things I can help you with:\"\n",
    "        \n",
    "        #CONFUSED RESPONSE\n",
    "        return f\"I'm not sure what you're asking, {user_model.name}. Could you please rephrase?\\nIf you need documentation let me know\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06db83f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"Matthew Y\"\n",
    "user_data_file = user_id + '.pkl'\n",
    "assistant = PersonalAssistant(user_data_file)\n",
    "\n",
    "interact_with_chatbot(assistant, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f4c060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

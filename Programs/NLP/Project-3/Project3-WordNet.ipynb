{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e02388d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.book import *\n",
    "import math\n",
    "\n",
    "#If download needed\n",
    "#nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80b8ad70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWordNet is a large database of a hierarchical organization of words and their relations to other words.\\nIt has useful associated data such as Synsets which are synonyms of the word (car - automobile), glosses\\nwhich are short definitions, and their relations to other words.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 - Write a 2-3 sentence summary of WordNet\n",
    "'''\n",
    "WordNet is a large database of a hierarchical organization of words and their relations to other words.\n",
    "It has useful associated data such as Synsets which are synonyms of the word (car - automobile), glosses\n",
    "which are short definitions, and their relations to other words.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca59a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('deoxyribonucleic_acid.n.01')]\n"
     ]
    }
   ],
   "source": [
    "#2 - Select a noun. Output all synsets\n",
    "noun_synset = wn.synsets('DNA')\n",
    "print(noun_synset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f061799a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definition:  (biochemistry) a long linear polymer found in the nucleus of a cell and formed from nucleotides and shaped like a double helix; associated with the transmission of genetic information \n",
      "\n",
      "Examples:  ['DNA is the king of molecules'] \n",
      "\n",
      "Lemmas:  [Lemma('deoxyribonucleic_acid.n.01.deoxyribonucleic_acid'), Lemma('deoxyribonucleic_acid.n.01.desoxyribonucleic_acid'), Lemma('deoxyribonucleic_acid.n.01.DNA')] \n",
      "\n",
      "Synsets going to the top:\n",
      "Synset('polymer.n.01')\n",
      "Synset('compound.n.02')\n",
      "Synset('chemical.n.01')\n",
      "Synset('material.n.01')\n",
      "Synset('substance.n.01')\n",
      "Synset('matter.n.03')\n",
      "Synset('physical_entity.n.01')\n",
      "Synset('entity.n.01')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFor nouns the definition seems like a pretty standard explanation for what the object is,\\nthe example for the noun I used was a list with a single element string which suggests there may be multiple examples for\\nsome words. The Lemmas are all the root of dog but in different forms, with one being the binomial name \"Canis_familiaris\".\\nThe synsets seem to be words that are synonyms that seem to vary in relevance from word to word.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 - Select one synset from the list of synsets. Extract its definition, usage examples, and lemmas.\n",
    "synset = noun_synset[0]\n",
    "\n",
    "print(\"Definition: \", synset.definition(), '\\n')\n",
    "print(\"Examples: \", synset.examples(), '\\n')\n",
    "print(\"Lemmas: \", synset.lemmas(), \"\\n\")\n",
    "\n",
    "#From your selected synset, traverse up the WordNet hierarchy as far as you can outputting the synsets as you go.\n",
    "top = list(wn.all_synsets('n'))[0] # Find the top of the hierarchy\n",
    "curr_hypernym = synset.hypernyms()[0]\n",
    "\n",
    "print(\"Synsets going to the top:\")\n",
    "while curr_hypernym:\n",
    "    print(curr_hypernym)\n",
    "    if curr_hypernym == top:\n",
    "        break\n",
    "    if curr_hypernym.hypernyms():\n",
    "        curr_hypernym = curr_hypernym.hypernyms()[0]\n",
    "\n",
    "#Write a few sentences observing the way that WordNet is organized for nouns.\n",
    "'''\n",
    "For nouns the definition seems like a pretty standard explanation for what the object is,\n",
    "the example for the noun I used was a list with a single element string which suggests there may be multiple examples for\n",
    "some words. The Lemmas are all the root of dog but in different forms, with one being the binomial name \"Canis_familiaris\".\n",
    "The synsets seem to be words that are synonyms that seem to vary in relevance from word to word.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8eae78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypernyms:  [Synset('polymer.n.01')] \n",
      "\n",
      "Hyponyms:  [Synset('complementary_dna.n.01'), Synset('episome.n.01'), Synset('exon.n.01'), Synset('intron.n.01'), Synset('junk_dna.n.01'), Synset('operon.n.01'), Synset('recombinant_deoxyribonucleic_acid.n.01'), Synset('sticky_end.n.01'), Synset('transposon.n.01')] \n",
      "\n",
      "Meronyms:  [Synset('base_pair.n.01'), Synset('gene.n.01'), Synset('nucleic_acid.n.01')] \n",
      "\n",
      "Holonyms:  []\n"
     ]
    }
   ],
   "source": [
    "#4 - Output the following or empty list if DNE: Hypernyms, Hyponyms, Meronyms, Holonyms, Antonym\n",
    "print('Hypernyms: ', synset.hypernyms(), '\\n')\n",
    "print('Hyponyms: ', synset.hyponyms(), '\\n')\n",
    "print('Meronyms: ', synset.part_meronyms(), '\\n')\n",
    "print('Holonyms: ', synset.part_holonyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3acce674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('thinking.n.01'), Synset('think.v.01'), Synset('think.v.02'), Synset('think.v.03'), Synset('remember.v.01'), Synset('think.v.05'), Synset('think.v.06'), Synset('intend.v.01'), Synset('think.v.08'), Synset('think.v.09'), Synset('think.v.10'), Synset('think.v.11'), Synset('think.v.12'), Synset('think.v.13'), Synset('intelligent.s.04')]\n"
     ]
    }
   ],
   "source": [
    "#5 - Select a verb. Output all synsets\n",
    "verb_synset = wn.synsets('Thinking')\n",
    "print(verb_synset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21565f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definition:  the process of using your mind to consider something carefully \n",
      "\n",
      "Examples:  ['thinking always made him frown', 'she paused for thought'] \n",
      "\n",
      "Lemmas:  [Lemma('thinking.n.01.thinking'), Lemma('thinking.n.01.thought'), Lemma('thinking.n.01.thought_process'), Lemma('thinking.n.01.cerebration'), Lemma('thinking.n.01.intellection'), Lemma('thinking.n.01.mentation')] \n",
      "\n",
      "Synsets going to the top:\n",
      "Synset('higher_cognitive_process.n.01')\n",
      "Synset('process.n.02')\n",
      "Synset('cognition.n.01')\n",
      "Synset('psychological_feature.n.01')\n",
      "Synset('abstraction.n.06')\n",
      "Synset('entity.n.01')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nWordNet seems to be organized pretty similarly to nouns.\\nThe definitions, examples, and lemmas fit what I would expect.\\nThere are two examples for this verb where the noun had \\none.\\nThat may be because there's more nuance in how they're \\nused rather than a definable object like a noun.\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6 - Select one syset from the list of synsets, extract its definition, usage examples, and lemmas\n",
    "synset = verb_synset[0]\n",
    "\n",
    "print(\"Definition: \", synset.definition(), '\\n')\n",
    "print(\"Examples: \", synset.examples(), '\\n')\n",
    "print(\"Lemmas: \", synset.lemmas(), \"\\n\")\n",
    "\n",
    "#From your selected synset, traverse up the WordNet hierarchy as far as you can outputting the synsets as you go.\n",
    "curr_hypernym = synset.hypernyms()[0]\n",
    "\n",
    "print(\"Synsets going to the top:\")\n",
    "while curr_hypernym:\n",
    "    print(curr_hypernym)\n",
    "    if curr_hypernym == top:\n",
    "        break\n",
    "    if curr_hypernym.hypernyms():\n",
    "        curr_hypernym = curr_hypernym.hypernyms()[0]\n",
    "\n",
    "#Write a few sentences observing the way that WordNet is organized for verbs.\n",
    "'''\n",
    "WordNet seems to be organized pretty similarly to nouns.\n",
    "The definitions, examples, and lemmas fit what I would expect.\n",
    "There are two examples for this verb where the noun had \n",
    "one.\n",
    "That may be because there's more nuance in how they're \n",
    "used rather than a definable object like a noun.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae4f70e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking\n",
      "thinking\n",
      "think\n",
      "thinking r\n",
      "thinking n\n"
     ]
    }
   ],
   "source": [
    "#7 - Use morphy to find as many different forms of the word as you can\n",
    "word = 'thinking'\n",
    "\n",
    "print(wn.morphy(word))\n",
    "print(wn.morphy(word, wn.ADJ))\n",
    "print(wn.morphy(word, wn.VERB))\n",
    "print(wn.morphy(word), wn.ADV)\n",
    "print(wn.morphy(word), wn.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfd907d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wu-Palmer Similarity:  0.5217391304347826 \n",
      "\n",
      "Lesk Algorithm:  Synset('lion.n.02')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe Wu-Palmer similarity showed a pretty decent similarity between Tiger and Lion at .52.\\nThis makes sense, and the score reflects the underlying similarities between the two.\\nFor the Lesk algorithm I used the definition of a lion for my sentence and\\nit returned lion which follows the expected result given the inputs and their overlap.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8 - Select two words that you think might be similar. Find the specific synsets you are interested in\n",
    "word1 = wn.synsets('Tiger')[0]\n",
    "word2 = wn.synsets('Lion')[0]\n",
    "\n",
    "#Run the Wu-Palmer similarity metric and the Lesk algorithm\n",
    "print(\"Wu-Palmer Similarity: \", wn.wup_similarity(word1, word2), '\\n')\n",
    "\n",
    "sent = word1.definition()\n",
    "print(\"Lesk Algorithm: \", lesk(sent, \"Lion\"))\n",
    "\n",
    "#Write a few sentences with your observations\n",
    "'''\n",
    "The Wu-Palmer similarity showed a pretty decent similarity between Tiger and Lion at .52.\n",
    "This makes sense, and the score reflects the underlying similarities between the two.\n",
    "For the Lesk algorithm I used the definition of a lion for my sentence and\n",
    "it returned lion which follows the expected result given the inputs and their overlap.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5213e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity scores for all senti-synsets of love\n",
      "<love.n.01: PosScore=0.625 NegScore=0.0>\n",
      "<love.n.02: PosScore=0.375 NegScore=0.0>\n",
      "<beloved.n.01: PosScore=0.125 NegScore=0.0>\n",
      "<love.n.04: PosScore=0.25 NegScore=0.0>\n",
      "<love.n.05: PosScore=0.0 NegScore=0.0>\n",
      "<sexual_love.n.02: PosScore=0.0 NegScore=0.0>\n",
      "<love.v.01: PosScore=0.5 NegScore=0.0>\n",
      "<love.v.02: PosScore=1.0 NegScore=0.0>\n",
      "<love.v.03: PosScore=0.625 NegScore=0.0>\n",
      "<sleep_together.v.01: PosScore=0.375 NegScore=0.125>\n",
      "\n",
      "Polarity for each word in sentence:  the fox is blue and red\n",
      "<fox.n.01: PosScore=0.0 NegScore=0.0>\n",
      "<be.v.01: PosScore=0.25 NegScore=0.125>\n",
      "<blue.n.01: PosScore=0.0 NegScore=0.0>\n",
      "<red.n.01: PosScore=0.0 NegScore=0.375>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nIt seems like the positivity and negatively vary pretty heavily based on definition.\\nSome colors such as red it considers \"negative\" while some neutral like blue.\\nThis is useful for analyzing the tone and sentiment of text, if a given text\\nhas many negative scoring words it\\'s more likely the tone is also negative.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9 - Write a couple of sentences about SentiWordNet, describing its functionality and possible use cases\n",
    "'''\n",
    "SentiWordNet is built on top of WordNet and acts as a sentiment analyzer.\n",
    "Given text it can try to dicern whether the tone is positive, negative or neutral.\n",
    "There are many possible use-cases for sentiment analysis such as chat-bots or analyzing customer reviews.\n",
    "'''\n",
    "\n",
    "# Select an emotionally charged word. Find its senti-synsets and output the polarity scores for each word\n",
    "word = 'love'\n",
    "print(\"Polarity scores for all senti-synsets of\", word)\n",
    "senti_list = list(swn.senti_synsets(word)) \n",
    "for item in senti_list:\n",
    "    print(item)\n",
    "print()\n",
    "\n",
    "# Make up a sentence. Output the polarity for each word in the sentence\n",
    "sentence = \"the fox is blue and red\"\n",
    "\n",
    "print(\"Polarity for each word in sentence: \", sentence)\n",
    "\n",
    "sentence = sentence.split()\n",
    "\n",
    "for word in sentence:\n",
    "    if(len(list(swn.senti_synsets(word)))) > 0:\n",
    "        first_element = list(swn.senti_synsets(word))[0]\n",
    "        print(first_element)\n",
    "\n",
    "\n",
    "# Write a couple of sentences about your observations of the scores and the utility of knowing these scores in an NLP application.\n",
    "'''\n",
    "It seems like the positivity and negatively vary pretty heavily based on definition.\n",
    "Some colors such as red it considers \"negative\" while some neutral like blue.\n",
    "This is useful for analyzing the tone and sentiment of text, if a given text\n",
    "has many negative scoring words it's more likely the tone is also negative.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88776d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocations for text4: \n",
      "United States; fellow citizens; years ago; four years; Federal\n",
      "Government; General Government; American people; Vice President; God\n",
      "bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "tribes; public debt; foreign nations\n",
      "None \n",
      "\n",
      "p(fellow citizens) =  0.006084788029925187\n",
      "p(fellow) =  0.013665835411471322\n",
      "p(citizens) =  0.026932668329177057\n",
      "pmi =  4.0472042737811735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe probability of each word seems low but is semi-frequent given the number of words.\\nWith a PMI of 4.04 that means that the probability of \"fellow\" being followed by \"citizens\"\\nis relatively high. \\nThis whenever we see the word \"fellow\" one common possible follow up word given text4 would be \"citizens\"\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 - Write a couple of sentences about what a collocation is\n",
    "'''\n",
    "Collocation is how words can mean very difference things when brought together.\n",
    "Even if two words are negative on their own, when combined it could result in a positive statement.\n",
    "It's also possible two words are a completely different noun or object when put together.\n",
    "'''\n",
    "\n",
    "#  Output collocations for text4,the Inaugural corpus.\n",
    "print('Collocations for text4: ')\n",
    "print(text4.collocations(), '\\n')\n",
    "\n",
    "#  Select one of the collocations identified by NLTK. Calculate mutual information.\n",
    "text = ' '.join(text4.tokens)\n",
    "\n",
    "words = len(set(text4))\n",
    "pXY = text.count('fellow citizens')/words\n",
    "print(\"p(fellow citizens) = \",pXY )\n",
    "pX = text.count('fellow')/words\n",
    "print(\"p(fellow) = \", pX)\n",
    "pY = text.count('citizens')/words\n",
    "print('p(citizens) = ', pY)\n",
    "pmi = math.log2(pXY / (pX * pY))\n",
    "print('pmi = ', pmi)\n",
    "\n",
    "# Write commentary on the results of the mutual information formula and your interpretation. \n",
    "'''\n",
    "The probability of each word seems low but is semi-frequent given the number of words.\n",
    "With a PMI of 4.04 that means that the probability of \"fellow\" being followed by \"citizens\"\n",
    "is relatively high. \n",
    "This whenever we see the word \"fellow\" one common possible follow up word given text4 would be \"citizens\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacef09c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
